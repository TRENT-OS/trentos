//------------------------------------------------------------------------------
//
// Generic Jenkins Pipeline Script
//
// Copyright (C) 2019, Hensoldt Cyber GmbH
//
//-------------------------------------------------------------------------------

// Parameters from job:
//
//    BRANCH_OR_COMMIT
//    PLATFORM
//    JENKINSFILE
//    TEST_SYSTEM
//    TEST_SCRIPT

params.each { println it.key + " = " + it.value }

def test_script = TEST_SCRIPT ?: (TEST_SYSTEM+'.py')
def SYSTEM_IMAGE  = 'build-' + PLATFORM + '-Debug-' + TEST_SYSTEM
def compile_commands_file = SYSTEM_IMAGE + '/compile_commands.json'

def info_str = BRANCH_OR_COMMIT+', '+PLATFORM+', '+TEST_SYSTEM

addShortText \
    text: info_str, \
    background: "khaki", \
    border: 1, \
    borderColor: "gray", \
    color: "black"


manager.createSummary("text.gif").appendText(
    '<table style="border: 1px solid black; border-collapse: collapse;">'+
        ['BRANCH_OR_COMMIT',
         'PLATFORM',
         'JENKINSFILE',
         'TEST_SYSTEM',
         'TEST_SCRIPT',
        ].collect{
            '<tr>'+
                '<td style="border: 1px solid black"><b><code>'+it+'</code></b></td>'+
                '<td style="border: 1px solid black">'+(evaluate(it)?:'<i>(null)</i>')+'</td></tr>'
        }.join('') +
    '</table>')



//------------------------------------------------------------------------------
// Docker
//------------------------------------------------------------------------------
//
// Notes:
// * bind the localtime to docker container to avoid problems of gaps between
//   the localtime of the container and the host.
// * add user to group "stack" (1001) in order to grant usage of Haskell stack
//   in the docker image
//
// ToDo
// * why are sudo right needed in the test container
//

def DOCKER_BASE = 'docker:5000'
def DOCKER_REGISTRY = 'https://' + DOCKER_BASE

def DOCKER_BUILD_ENV = [
    registry: DOCKER_REGISTRY,
    image:    DOCKER_BASE + '/trentos_build:trentos_1.2',
    args:     ['-v /etc/localtime:/etc/localtime:ro',
               '--group-add=stack'
              ].join(' ')
]

def DOCKER_TEST_ENV  = [
    registry: DOCKER_REGISTRY,
    image:    DOCKER_BASE + '/trentos_test:20210303',
    args:     ['-v /home/jenkins/.ssh/:/home/jenkins/.ssh:ro',
               '-v /etc/localtime:/etc/localtime:ro',
               '--network=bridge',
               '--cap-add=NET_ADMIN',
               '--cap-add=NET_RAW',
               '--device=/dev/net/tun',
               '--group-add=sudo'
              ].join(' ')
]


//------------------------------------------------------------------------------
// Pipeline
//------------------------------------------------------------------------------

//------------------------------------------------------------------------------
def print_step_info(name) { echo "#################### " + name }


//------------------------------------------------------------------------------
def do_notify_bitbucket()
{
    // the StashNotifier requires to run in a node block, which should not be
    // necessary technically. See also the open issue issue at
    // https://github.com/jenkinsci/stashnotifier-plugin/issues/234 which

    if (env.NODE_NAME)
    {
        notifyBitbucket();
    }
    else
    {
        node { notifyBitbucket() }
    }
}


//------------------------------------------------------------------------------
pipeline {
    agent none
    options {
        skipDefaultCheckout true

        // unfortunately there is no way to have build discarding conditional
        // for development branches only, so "master" and "integration" would
        // keep their builds. The potential work around is having a conditional
        // stage where "master" and "integration" push a package to an artifact
        // server, which then preserves this.
        buildDiscarder(logRotator(numToKeepStr: '100'))
    }
    stages {
        stage('Build_stage'){
            agent { label "build" }
            stages {
                stage('clean_checkout') {
                    steps {
                        print_step_info env.STAGE_NAME
                        do_notify_bitbucket()
                        buildName BRANCH_OR_COMMIT+' '+TEST_SYSTEM+' '+PLATFORM
                        cleanWs()

                        // everything is in separate folders to avoid file
                        // conflicts. Sources are checked out into "scm-src",
                        // builds should generate "build-xxx" folders, tests
                        // will use "workspace_test" ...
                        dir('scm-src') {
                            checkout([
                                $class: 'GitSCM',
                                branches: scm.branches,
                                doGenerateSubmoduleConfigurations: false,
                                extensions: [[
                                  $class: 'SubmoduleOption',
                                  disableSubmodules: false,
                                  parentCredentials: true,
                                  recursiveSubmodules: true,
                                  reference: '',
                                  trackingSubmodules: false,
                                  threads: 4
                                ]],
                                submoduleCfg: [],
                                userRemoteConfigs: scm.userRemoteConfigs
                              ])
                        }
                    }
                }
                stage('build') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registry
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info env.STAGE_NAME
                        withEnv(["BUILD_PLATFORM=${PLATFORM}"]) {
                            sh 'scm-src/build.sh ' + TEST_SYSTEM
                        }
                    }
                }
                stage('static_analyzer') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registry
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info env.STAGE_NAME
                        catchError(buildResult: 'SUCCESS', stageResult: 'FAILURE') {
                            sh 'scm-src/check_static_analyzer.sh ' + compile_commands_file
                        }
                    }
                }
                stage('prepare_test') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_BUILD_ENV.registry
                            image DOCKER_BUILD_ENV.image
                            args DOCKER_BUILD_ENV.args
                        }
                    }
                    steps {
                        print_step_info env.STAGE_NAME
                        sh 'scm-src/test.sh prepare'
                    }
                }
                stage('test_doc') {
                    agent {
                        docker {
                            reuseNode true
                            alwaysPull true
                            registryUrl DOCKER_TEST_ENV.registry
                            image DOCKER_TEST_ENV.image
                            args DOCKER_TEST_ENV.args
                        }
                    }
                    steps {
                        print_step_info env.STAGE_NAME
                        sh 'scm-src/test.sh doc'
                    }
                }

                stage('stash_cleanup') {
                    steps {
                        print_step_info env.STAGE_NAME
                        stash \
                            name: 'test_package', \
                            includes: [ 'scm-src/**',
                                        'workspace_test/**',
                                        [ 'elfloader/elfloader',
                                          'images/os_image.bin',
                                           compile_commands_file,
                                          'kernel/kernel_all.c',
                                          'kernel/kernel_all.i',
                                          'kernel/kernel.elf',
                                          'kernel/kernel.dts',
                                          'kernel/gen_config/**',
                                          'kernel/gen_headers/**',
                                          'kernel/generated/**',
                                          'os_system/**',
                                        ].collect{ SYSTEM_IMAGE + '/' + it }.join(',')
                                      ].join(',')
                        cleanWs()
                    }
                }
            }
        }
        stage('test') {
            agent {
                docker {
                    label "test"
                    reuseNode true
                    alwaysPull true
                    registryUrl DOCKER_TEST_ENV.registry
                    image DOCKER_TEST_ENV.image
                    args DOCKER_TEST_ENV.args
                }
            }
            steps {
                print_step_info env.STAGE_NAME
                sh 'rm -rf *' // using cleanWs() seems to kill the workspace
                unstash 'test_package'
                catchError(buildResult: 'UNSTABLE', stageResult: 'FAILURE') {
                    // It can happen that the test framework doesn't kill all threads
                    // it started, and these threads keep this stage from finishing.
                    // The highest test execution time in the last 10 integration runs
                    // was 310 seconds for test_uart, so 420 seconds looks like a
                    // good value to start from.
                    timeout(time: 420, unit: 'SECONDS')
                    {
                        withEnv([
                            "BUILD_PLATFORM=${PLATFORM}",
                            "TEST_LOGS_DIR=test-logs"
                        ]) {
                            sh 'scm-src/test.sh run ' + test_script
                        }
                    }
                }
                stash \
                    name: 'test_result_package', \
                    includes: ['test-logs/**', SYSTEM_IMAGE+'/**'].join(',')
                cleanWs()
            }
        }
    }
    post {
        always {
            node('test')
            {
                print_step_info 'archive artifacts'
                cleanWs()

                // there might be no stash if things failed badly
                catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
                    unstash 'test_result_package'
                }

                // get the current build's log. One day we should find a nicer
                // way for this ...
                sh 'wget -q --no-check-certificate -O build.log ' + BUILD_URL + 'consoleText'

                sh 'tar --ignore-failed-read -cjf package.bz2 ' +
                        ['build.log',
                         SYSTEM_IMAGE + '/',
                         'test-logs/',
                        ].join(' ')
                archiveArtifacts artifacts: 'package.bz2', fingerprint: true
                cleanWs()
                do_notify_bitbucket()
            }
        }
    }
}
